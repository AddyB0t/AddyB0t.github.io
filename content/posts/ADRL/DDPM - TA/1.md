---
title: "Score matching"
math: true
draft: false
---

## Recall - Variational framework

![DDPM](1.jpg)
![DDPM](2.jpg)

## Sampling as optimization

We can think of sampling as getting the most probable sample from a distribution.

$$x^* = \mathop{\arg \max}_{x} p(x)$$  

$$x^* = \mathop{\arg \max}_{x} \log p(x)$$

$$x^* = \mathop{\arg \min}_{x} - \log p(x)$$

we can solve this using gradient descent.

$$x_{t+1} = x_t + \alpha \cdot \nabla \log p(x_t)$$

here, $\alpha$ is the learning rate.

We can write Langevian equation as:


$$x_{t+1} = x_t + \alpha \cdot \nabla_x \log p(x_t) + \sqrt{2\alpha} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$ 

where:

- $\nabla_x \log p(x_t)$ is the gradient of the log probability evaluated at $x_t$.
- $\sqrt{2\alpha} \epsilon$ is the stochastic term introducing randomness, ensuring exploration of the sample space.
- $\epsilon \sim \mathcal{N}(0, I)$ is the noise term drawn from a standard normal distribution, providing the stochasticity in the sampling process.

## Score matching


Score function is the gradient of the log probability with respect to the data.

$$s(x) = \nabla_x \log p(x)$$

we want to estimate the score function $s(x)$ to solve:

$$x_{t+1} = x_t + \alpha \cdot \nabla_x \log p(x_t) + \sqrt{2\alpha} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$

The score function can be interpreted as a force that drives the sample towards higher probability regions.

We try to estimate the score function by learning a neural network to predict the score function.

To learn the score function, we need a loss function that measures the difference between the estimated score function and the true score function.

## Naive score matching or explicit score matching
*Explicit means something that is clearly and directly stated, leaving no room for confusion or doubt.


$$J_{ESM}(\theta) = \mathbb{E}_{p(x)} \left[ \left\|  \hat{s}(x; \theta) - s(x) \right\|^2 \right]$$

where,

- $s(x)$ is the true score function.
- $\hat{s}(x)$ is the estimated score function.

This loss function is not tractable because we don't know the true score function.

## Implicit score matching
*Implicit means something that is implied or suggested but not directly expressed.

*We will not prove the following derivation, but it is there in class notes.

The implicit score matching loss function can be written as:

$$J_{ISM}(\theta) = \mathbb{E}_{p(x)} \left[ \frac{1}{2} \| \hat{s}(x; \theta) \|^2 + \text{tr}(\nabla_x \hat{s}(x; \theta)) \right] + C$$

As per the theorm this can be written as:

$$J_{ISM}(\theta) = J_{ESM}(\theta)  + C$$

Where:
- $\hat{s}(x; \theta)$ is the estimated score function
- $\text{tr}(\nabla_x \hat{s}(x; \theta))$ is the trace of the Jacobian of the estimated score function
- $C$ is a constant term independent of $\theta$

Also following assumptions were made for proving the theorm:
1. $p(x)$ is differentiable
2. $\mathbb{E}_{p(x)}[\|\nabla_x \log p(x)\|^2] < \infty$ for any $\theta$ & 
   $\mathbb{E}_{p(x)}[\|\hat{s}(x; \theta)\|^2] < \infty$ for any $\theta$
3. $p(x)\hat{s}(x; \theta) \to 0$ for any $\theta$ as $\|x\| \to \infty$



This formulation allows us to optimize the score function without explicitly knowing the true score function $\nabla_x \log p(x)$. The trace term $\text{tr}(\nabla_x \hat{s}(x; \theta))$ comes from the divergence of the score function, which is equal to $\nabla_x \cdot (\nabla_x \log p(x)) = \nabla_x^2 \log p(x)$.

















