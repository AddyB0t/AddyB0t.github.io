---
title: "ODEs/SDEs"
math: true
draft: false
---
# 24 Oct 2024
# Conversion of discrete/ iterative equations to continous forms
 This topic comes under stochastic calculus, which deals with functions whose derivatives yield random vectors rather than deterministic points. In traditional calculus, when we take the derivative of a function at a point, we get a fixed value that represents the instantaneous rate of change. However, in stochastic calculus, the derivative at any point is itself a random variable, making the behavior more complex and unpredictable.

 The key difference lies in the nature of the underlying processes:
 - Deterministic processes follow fixed paths that can be precisely predicted
 - Stochastic processes involve randomness at each step, leading to different possible paths
 
 This randomness is essential for modeling real-world phenomena like:
 - Financial market fluctuations
 - Particle diffusion in physics
 - Population dynamics in biology
 - And notably, the noise addition/removal process in diffusion models

# Big Picture
![DDPM](8.1.jpg)

# Another example
Let's look at another example of converting a discrete equation to continuous form:

1. Starting with the discrete equation:
   $$x_i = x_{i-1} - \beta_{i-1}\nabla f(x_{i-1})$$
   where $\beta$ is the gradient descent step size

2. Make it continuous by substituting:
   $$x_i = x(\frac{i}{N}), \quad \Delta t = \frac{1}{N}, \quad \beta_{i-1} = \beta(t)\Delta t$$

3. This gives us:
   $$x(t + \Delta t) = x(t) - \beta(t)\Delta t\nabla f(x(t))$$

4. Rearranging to get the differential form:
   $$\frac{x(t + \Delta t) - x(t)}{\Delta t} = -\beta(t)\nabla f(x(t))$$

5. Taking the limit as $\Delta t \to 0$:
   $$\frac{dx(t)}{dt} = -\beta(t)\nabla f(x(t))$$

6. Finally, we can write this in the more compact differential form:
   $$dx = -\beta(t)\nabla f(x(t))dt$$

This demonstrates how a discrete gradient descent step can be viewed as a discretization of a continuous ordinary differential equation (ODE).

# Stochastic Differential Equations (SDEs)
Now let's understand the formal definition of SDEs:

1. An Ordinary Differential Equation (ODE) can be written as:
   $$\frac{dx(t)}{dt} = f(x,t)$$
   or in differential form:
   $$dx = f(x,t)dt$$

2. A Stochastic Differential Equation (SDE) adds a noise term:
   $$\frac{dx(t)}{dt} = f(x,t) + g(x,t)dW(t)$$
   or in differential form:
   $$dx = f(x,t)dt + g(x,t)dB_t$$

   where:
   - $f(x,t)$ is called the drift term (deterministic component that describes the average behavior)
   - $g(x,t)$ is called the diffusion term (controls the magnitude of random fluctuations)
   - $W(t)$ is a Wiener process (Brownian noise) - a continuous-time stochastic process
   - $B_t$ is a Brownian motion, $dB_t$ is the increment of Brownian motion where 
     $$dB_t \sim N(0,dt)$$
     $$dB_t = \sqrt{dt}\epsilon \quad \text{where} \quad \epsilon \sim N(0,1)$$

Key points about SDEs:
- An ODE is a special case where $g(x,t) = 0$
- The SDE is a stochastic process
- A stochastic process at time t can be seen as a distribution of random variables

We can define important properties of an SDE:
1. Mean/drift:
   $$m(t) = \mathbb{E}[x(t)] \leftarrow f(x,t)$$

2. Variance:
   $$v(t) = \text{Var}(x(t)) \leftarrow g(x,t)$$

This provides one way to analyze and understand SDEs.

## Preliminaries for Brownian Motion
### Brownian Motion definition
![DDPM](9.1.jpg)

A standard Brownian Motion (BM) is a random process $X = \{X_t : t \in [0,\infty)\}$ with state space $\mathbb{R}$ that satisfies the following properties:

1. $X_0 = 0$ with probability 1
   - *The process always starts at zero*

2. Has stationary increments:
   - For any $t \in [0,\infty)$, the distribution of $X_t - X_s$ only depends on the time difference $(t-s)$
   - *The behavior of changes doesn't depend on when we start observing*

3. Has independent increments:
   - For any times $t_1 < t_2 < ... < t_n \in [0,\infty)$
   - The increments $X_{t_2} - X_{t_1}, X_{t_3} - X_{t_2}, ..., X_{t_n} - X_{t_{n-1}}$ are independent
   - For any non-overlapping time intervals
   - *What happens in one time period doesn't affect what happens in another*

4. For any $t \in [0,\infty)$:
   $X_t \sim \mathcal{N}(0,t)$ (Normal distribution with mean 0 and variance t)
   - *The position at any time follows a normal distribution with variance growing linearly with time*

5. With probability 1, $t \mapsto X_t$ is continuous on $[0,\infty)$
   - *The path is continuous - no sudden jumps*

Important properties that follow from these definitions:

- $X_t - X_s \sim \mathcal{N}(0,t-s)$
  - *The change over any interval follows a normal distribution*
- $X_t \sim \mathcal{N}(0,t)$
  - *The position at any time follows a normal distribution*
- $X_{t+s} - X_s \perp X_s$ (independence of increments)
  - *Future changes are independent of current position*

# Lets talk about $B_t$ - What it is not 
Let's consider how Brownian motion behaves when we look at small time intervals:

Consider $B_{t+h} - B_t$ where:
- $h > 0$: Looking at a small time step
- $B_{t+h} - B_t \sim B_h$ (from stationarity)
- $h < 0$: $B_{t+h} - B_t \sim -B_{-h}$ (from symmetry)

When we combine both:
$B_{t+h} - B_t \sim B_{|h|}$

Therefore:
$\frac{B_{t+h} - B_t}{h} \sim \mathcal{N}(0,{|h|})$

$$\frac{B_{t+h} - B_t}{h} \sim \frac{1}{h}\mathcal{N}(0,|h|) = \mathcal{N}(0,\frac{1}{h})$$

Therefore, the variance is:
$$\text{Var}(\frac{B_{t+h} - B_t}{h}) = \text{Var}(\frac{1}{h}B_{|h|}) = \frac{1}{h^2}\text{Var}(B_{|h|}) = \frac{1}{h^2}|h| = \frac{1}{h}$$

Taking the limit as h approaches 0:
$$\lim_{h \to 0} \text{Var}(\frac{B_{t+h} - B_t}{h}) = \lim_{h \to 0} \frac{1}{h} = \infty$$

**Theorem**: With probability 1, Brownian motion $B_t$ is nowhere differentiable on $[0,\infty)$.

This means that **Brownian motion is not differentiable** because:
1. The variance of the rate of change becomes infinite as we look at smaller time intervals
2. This means the rate of change becomes arbitrarily large and fluctuates wildly
3. No well-defined derivative can exist under these conditions

Hence, $\frac{B_{t+h} - B_t}{h}$ does not converge in distribution (weakest form of convergence).

# Lets talk about $B_t$ - What it is
While we cannot talk about $B_t$ in terms of derivatives, we can define it in terms of perturbations:

Let's define a perturbation $W_t^\epsilon$ as:

$$W_t^\epsilon = \frac{B_{t+\epsilon} - B_t}{\epsilon}$$

where $\epsilon$ represents a small time increment.

As $\epsilon \to 0$, we can write:

$$W_t = \lim_{\epsilon \to 0} W_t^\epsilon = \lim_{\epsilon \to 0} \frac{B_{t+\epsilon} - B_t}{\epsilon}$$

This is often written informally as:

$$W_t \stackrel{\Delta}{=} \frac{dB_t}{dt}$$

Note: This is an abuse of notation since $B_t$ is not differentiable.

We can think of $W_t$ as "white noise", which is a random process with constant power spectral density. Mathematically, this is expressed as:

$$W_t \sim \frac{1}{\sqrt{dt}} \cdot \mathcal{N}(0,1)$$

The factor $\frac{1}{\sqrt{dt}}$ ensures that the process has infinite variance, a defining characteristic of white noise.

This understanding allows us to write the increment of Brownian motion more formally as:

$$dB_t = \sqrt{dt} \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0,1)$$

**This part was not done in the class properly*

Here, $\epsilon$ is a standard normal random variable that is independent for each infinitesimal time step. This formulation highlights how the magnitude of Brownian motion's increments scales with the square root of time, which is a fundamental property of Brownian motion.

This formulation helps us understand Brownian motion in terms of its increments rather than derivatives, which is mathematically sound and useful for applications.

## Another example - convert continuous SDE to discrete soln
The continuous stochastic differential equation (SDE) is given by:

$$dx = \epsilon \sqrt{dt} \quad // \text{cont eqn}$$

where $\epsilon \sim \mathcal{N}(0,1)$.

To convert this continuous SDE to a discrete solution, we consider the increments:

$$X_{t_{i+1}} - X_{t_i} = \sqrt{t_{i+1} - t_i} \cdot \epsilon$$

Assuming $t$ were not discrete, we can express it as:

$$X_{t_{i+1}} = X_{t_i} + \sqrt{t_{i+1} - t_i} \cdot \epsilon$$

Finally, for a discrete solution, we have:

$$x_{i+1} = x_i + \epsilon, \quad \epsilon \sim \mathcal{N}(0,1) \quad // \text{discrete soln}$$








